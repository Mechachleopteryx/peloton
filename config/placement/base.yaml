logging:
  level: info
  stdout: true

placement:
  http_port: 5293
  grpc_port: 5393
  task_dequeue_limit: 10
  task_dequeue_timeout: 100
  offer_dequeue_limit: 10
  max_placement_duration: 300s
  task_type: 0
  fetch_offer_tasks: false
  strategy: batch
  concurrency: 4
  max_rounds:
    unknown: 1
    batch: 1
    stateless: 5
    daemon: 5
    stateless: 0  # 0 Means no limit
  max_durations:
    unknown: 5m
    batch: 5m
    stateless: 5m
    daemon: 5m
    stateless: 5m

election:
  root: "/peloton"

health:
  heartbeat_interval: 5s

storage:
  mysql:
    user: peloton
    password: peloton
    database: peloton
    host: 127.0.0.1
    port: 8193
    migrations: storage/mysql/migrations/
    # max_batch_size_rows controls how many tasks are created/updated in 1
    # insert statement. Increasing this will improve startup times for high task
    # count jobs. WARNING: tuning this up beyond the threshold of MYSQL_PACKET_SIZE
    # may result in failed task creations
    max_batch_size_rows: 500
    conn_lifetime: 30s
  cassandra:
    # FIXME: need to increase batch size limit dynamically in cassandra (T968823)
    max_batch_size_rows: 1
    max_parallel_batches: 1000
    connection:
      contactPoints: ["127.0.0.1"]
      port: 9042
      consistency: LOCAL_QUORUM
      timeout: 10s
    store_name: peloton_test
    migrations: storage/cassandra/migrations/
  use_cassandra: false
  db_write_concurrency: 40
