// Copyright (c) 2019 Uber Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package aurorabridge

import (
	"context"
	"fmt"

	"github.com/pborman/uuid"
	"github.com/uber/peloton/.gen/peloton/api/v1alpha/job/stateless"
	statelesssvc "github.com/uber/peloton/.gen/peloton/api/v1alpha/job/stateless/svc"
	"github.com/uber/peloton/.gen/peloton/api/v1alpha/peloton"
	"github.com/uber/peloton/.gen/peloton/api/v1alpha/pod"
	podsvc "github.com/uber/peloton/.gen/peloton/api/v1alpha/pod/svc"
	pbquery "github.com/uber/peloton/.gen/peloton/api/v1alpha/query"
	"github.com/uber/peloton/.gen/thrift/aurora/api"
	"github.com/uber/peloton/util"

	"github.com/uber/peloton/aurorabridge/atop"
	"github.com/uber/peloton/aurorabridge/common"
	"github.com/uber/peloton/aurorabridge/concurrency"
	"github.com/uber/peloton/aurorabridge/label"
	"github.com/uber/peloton/aurorabridge/opaquedata"
	"github.com/uber/peloton/aurorabridge/ptoa"

	"github.com/pkg/errors"
	log "github.com/sirupsen/logrus"
	"github.com/uber-go/tally"
	"go.uber.org/thriftrw/ptr"
	"go.uber.org/yarpc/yarpcerrors"
)

var errUnimplemented = errors.New("rpc is unimplemented")

// ServiceHandler implements a partial Aurora API. Various unneeded methods have
// been left intentionally unimplemented.
type ServiceHandler struct {
	config        ServiceHandlerConfig
	metrics       *Metrics
	jobClient     statelesssvc.JobServiceYARPCClient
	podClient     podsvc.PodServiceYARPCClient
	respoolLoader RespoolLoader
}

// NewServiceHandler creates a new ServiceHandler.
func NewServiceHandler(
	config ServiceHandlerConfig,
	parent tally.Scope,
	jobClient statelesssvc.JobServiceYARPCClient,
	podClient podsvc.PodServiceYARPCClient,
	respoolLoader RespoolLoader,
) *ServiceHandler {

	config.normalize()

	return &ServiceHandler{
		config:        config,
		metrics:       NewMetrics(parent.SubScope("aurorabridge").SubScope("api")),
		jobClient:     jobClient,
		podClient:     podClient,
		respoolLoader: respoolLoader,
	}
}

// GetJobSummary returns a summary of jobs, optionally only those owned by a specific role.
func (h *ServiceHandler) GetJobSummary(
	ctx context.Context,
	role *string,
) (*api.Response, error) {

	result, err := h.getJobSummary(ctx, role)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"role": role,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetJobSummary error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) getJobSummary(
	ctx context.Context,
	role *string,
) (*api.Result, *auroraError) {

	var jobSummaries []*api.JobSummary

	query := &api.TaskQuery{Role: role}

	jobIDs, err := h.getJobIDsFromTaskQuery(ctx, query)
	if err != nil {
		return nil, auroraErrorf("get job ids from task query: %s", err)
	}

	for _, jobID := range jobIDs {
		jobInfo, err := h.getJobInfo(ctx, jobID)
		if err != nil {
			return nil, auroraErrorf("get job info for job id %q: %s",
				jobID.GetValue(), err)
		}

		// In Aurora, JobSummary.JobConfiguration.TaskConfig
		// is generated using latest "active" task. Reference:
		// https://github.com/apache/aurora/blob/master/src/main/java/org/apache/aurora/scheduler/base/Tasks.java#L133
		// but use JobInfo.JobSpec.DefaultSpec here to simplify
		// the querying logic.
		// TODO(kevinxu): Need to match Aurora's behavior?
		// TODO(kevinxu): Need to inspect InstanceSpec as well?
		podSpec := jobInfo.GetSpec().GetDefaultSpec()

		s, err := ptoa.NewJobSummary(jobInfo, podSpec)
		if err != nil {
			return nil, auroraErrorf("new job summary: %s", err)
		}

		jobSummaries = append(jobSummaries, s)
	}

	return &api.Result{
		JobSummaryResult: &api.JobSummaryResult{
			Summaries: jobSummaries,
		},
	}, nil
}

// GetTasksWithoutConfigs is the same as getTasksStatus but without the TaskConfig.ExecutorConfig
// data set.
func (h *ServiceHandler) GetTasksWithoutConfigs(
	ctx context.Context,
	query *api.TaskQuery,
) (*api.Response, error) {

	result, err := h.getTasksWithoutConfigs(ctx, query)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"query": query,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetTasksWithoutConfigs error")
	}
	return newResponse(result, err), nil
}

// getScheduledTaskResult represents output
// value returned on channel generated by
// getTasksWithoutConfigs and error if occured
type getScheduledTaskResult struct {
	task *api.ScheduledTask
	err  error
}

func (h *ServiceHandler) getTasksWithoutConfigs(
	ctx context.Context,
	query *api.TaskQuery,
) (*api.Result, *auroraError) {

	var scheduledTasks []*api.ScheduledTask
	var podStates []pod.PodState

	for s := range query.GetStatuses() {
		p, err := atop.NewPodState(s)
		if err != nil {
			return nil, auroraErrorf("new pod state: %s", err)
		}
		podStates = append(podStates, p)
	}

	jobIDs, err := h.getJobIDsFromTaskQuery(ctx, query)
	if err != nil {
		return nil, auroraErrorf("get job ids from task query: %s", err)
	}

	// TODO(kevinxu): Factor out to seperate function.
	for _, jobID := range jobIDs {
		jobInfo, err := h.getJobInfo(ctx, jobID)
		if err != nil {
			return nil, auroraErrorf("get job info for job id %q: %s",
				jobID.GetValue(), err)
		}

		// TODO(kevinxu): QueryPods api only returns pods from latest run,
		// while aurora returns tasks from all previous runs. Do we need
		// to make it consistent with aurora's behavior?
		pods, err := h.queryPods(
			ctx,
			jobID,
			podStates,
			jobInfo.GetSpec().GetInstanceCount(),
		)
		if err != nil {
			return nil, auroraErrorf(
				"query pods for job id %q with pod states %q: %s",
				jobID.GetValue(), podStates, err)
		}

		tasks, err := h.getScheduledTasks(ctx, jobInfo, pods)
		if err != nil {
			return nil, auroraErrorf("get tasks without configs: %s", err)
		}
		scheduledTasks = append(scheduledTasks, tasks...)
	}

	return &api.Result{
		ScheduleStatusResult: &api.ScheduleStatusResult{
			Tasks: scheduledTasks,
		},
	}, nil
}

// getScheduledTasks generates a list of Aurora ScheduledTask in a worker
// pool.
func (h *ServiceHandler) getScheduledTasks(
	ctx context.Context,
	jobInfo *stateless.JobInfo,
	podInfos []*pod.PodInfo,
) ([]*api.ScheduledTask, error) {

	var inputs []interface{}
	for _, p := range podInfos {
		inputs = append(inputs, p)
	}

	f := func(ctx context.Context, input interface{}) (interface{}, error) {
		podInfo, ok := input.(*pod.PodInfo)
		if !ok {
			return nil, fmt.Errorf("failed to cast input to pod info")
		}

		var ts []*api.ScheduledTask
		podName := podInfo.GetSpec().GetPodName()

		for i := 0; i < h.config.PodRunsDepth; i++ {
			var ancestorID *string
			var podID *peloton.PodID

			if len(ts) > 0 {
				if ancestorID = ts[len(ts)-1].AncestorId; ancestorID == nil {
					// No more ancestor tasks
					break
				}
			}

			if ancestorID != nil {
				podID = &peloton.PodID{Value: *ancestorID}
			}

			podEvents, err := h.getPodEvents(
				ctx,
				podName,
				podID,
			)
			if err != nil {
				return nil, fmt.Errorf(
					"get pod events for pod %q with pod id %q: %s",
					podName.GetValue(), podID.GetValue(), err)
			}
			if len(podEvents) == 0 {
				break
			}

			var t *api.ScheduledTask
			if i >= 1 {
				t, err = ptoa.NewScheduledTaskForPrevRun(podEvents)
			} else {
				t, err = ptoa.NewScheduledTask(jobInfo, podInfo, podEvents)
			}
			if err != nil {
				return nil, fmt.Errorf(
					"new scheduled task: %s", err)
			}
			ts = append(ts, t)
		}
		return ts, nil
	}

	outputs, err := concurrency.Map(
		ctx,
		concurrency.MapperFunc(f),
		inputs,
		h.config.GetTasksWithoutConfigsWorkers)
	if err != nil {
		return nil, err
	}

	var tasks []*api.ScheduledTask
	for _, o := range outputs {
		tasks = append(tasks, o.([]*api.ScheduledTask)...)
	}
	return tasks, nil
}

// GetConfigSummary fetches the configuration summary of active tasks for the specified job.
func (h *ServiceHandler) GetConfigSummary(
	ctx context.Context,
	job *api.JobKey) (*api.Response, error) {

	result, err := h.getConfigSummary(ctx, job)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"job": job,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetConfigSummary error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) getConfigSummary(
	ctx context.Context,
	jobKey *api.JobKey,
) (*api.Result, *auroraError) {
	jobID, err := h.getJobID(
		ctx,
		jobKey)
	if err != nil {
		return nil, auroraErrorf("unable to get jobID from jobKey: %s", err)
	}

	jobInfo, err := h.getJobInfo(ctx, jobID)
	if err != nil {
		return nil, auroraErrorf("unable to get jobInfo from jobID: %s", err)
	}

	podInfos, err := h.queryPods(
		ctx,
		jobID,
		nil,
		jobInfo.GetSpec().GetInstanceCount())
	if err != nil {
		return nil, auroraErrorf("unable to query pods using jobID: %s", err)
	}

	configSummary, err := ptoa.NewConfigSummary(
		jobInfo,
		podInfos)
	if err != nil {
		return nil, auroraErrorf("unable to get config summary from podInfos: %s", err)
	}

	return &api.Result{
		ConfigSummaryResult: &api.ConfigSummaryResult{
			Summary: configSummary,
		},
	}, nil
}

// GetJobs fetches the status of jobs. ownerRole is optional, in which case all jobs are returned.
func (h *ServiceHandler) GetJobs(
	ctx context.Context,
	ownerRole *string,
) (*api.Response, error) {

	result, err := h.getJobs(ctx, ownerRole)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"ownerRole": ownerRole,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetJobs error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) getJobs(
	ctx context.Context,
	ownerRole *string,
) (*api.Result, *auroraError) {

	var configs []*api.JobConfiguration

	query := &api.TaskQuery{Role: ownerRole}

	jobIDs, err := h.getJobIDsFromTaskQuery(ctx, query)
	if err != nil {
		return nil, auroraErrorf("get job ids from task query: %s", err)
	}

	for _, jobID := range jobIDs {
		jobInfo, err := h.getJobInfo(ctx, jobID)
		if err != nil {
			return nil, auroraErrorf("get job info for job id %q: %s",
				jobID.GetValue(), err)
		}

		// In Aurora, JobConfiguration.TaskConfig
		// is generated using latest "active" task. Reference:
		// https://github.com/apache/aurora/blob/master/src/main/java/org/apache/aurora/scheduler/base/Tasks.java#L133
		// but use JobInfo.JobSpec.DefaultSpec here to simplify
		// the querying logic.
		// TODO(kevinxu): Need to match Aurora's behavior?
		// TODO(kevinxu): Need to inspect InstanceSpec as well?
		podSpec := jobInfo.GetSpec().GetDefaultSpec()

		c, err := ptoa.NewJobConfiguration(jobInfo, podSpec)
		if err != nil {
			return nil, auroraErrorf("new job configuration: %s", err)
		}

		configs = append(configs, c)
	}

	return &api.Result{
		GetJobsResult: &api.GetJobsResult{
			Configs: configs,
		},
	}, nil
}

// GetJobUpdateSummaries gets job update summaries.
// This is the sequence in which jobUpdateQuery filters updates.
// - Get JobIDs using job key role and filter their updates
// - Get JobIDs using job key and filter their updates
// - If only update statuses are provided then filter all job updates
func (h *ServiceHandler) GetJobUpdateSummaries(
	ctx context.Context,
	jobUpdateQuery *api.JobUpdateQuery,
) (*api.Response, error) {

	jobUpdateDetails, err := h.getJobUpdateDetails(
		ctx,
		jobUpdateQuery,
		true, /* summary only */
	)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key": jobUpdateQuery,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetJobUpdateSummaries error")
	}

	var jobUpdateSummaries []*api.JobUpdateSummary
	for _, jobUpdateDetail := range jobUpdateDetails {
		jobUpdateSummaries = append(jobUpdateSummaries, jobUpdateDetail.GetUpdate().GetSummary())
	}

	return newResponse(&api.Result{
		GetJobUpdateSummariesResult: &api.GetJobUpdateSummariesResult{
			UpdateSummaries: jobUpdateSummaries,
		},
	}, err), nil
}

// GetJobUpdateDetails gets job update details.
// jobUpdateKey is marked to be deprecated from Aurora, and not used Aggregator
// It will be ignored to get job update details
func (h *ServiceHandler) GetJobUpdateDetails(
	ctx context.Context,
	key *api.JobUpdateKey,
	query *api.JobUpdateQuery,
) (*api.Response, error) {

	if key.IsSetJob() {
		query.JobKey = key.GetJob()
	}

	jobUpdateDetails, err := h.getJobUpdateDetails(
		ctx,
		query,
		false, /* summary only */
	)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key":   key,
				"query": query,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetJobUpdateDetails error")
	}

	return newResponse(&api.Result{
		GetJobUpdateDetailsResult: &api.GetJobUpdateDetailsResult{
			DetailsList: jobUpdateDetails,
		},
	}, err), nil
}

// GetJobUpdateDiff gets the diff between client (desired) and server (current) job states.
// TaskConfig is not set in GetJobUpdateDiffResult, since caller is not using it
// and fetching previous podspec is expensive
func (h *ServiceHandler) GetJobUpdateDiff(
	ctx context.Context,
	request *api.JobUpdateRequest) (*api.Response, error) {

	result, err := h.getJobUpdateDiff(ctx, request)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"request": request,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("GetJobUpdateDiff error")
	}

	return newResponse(result, err), nil
}

func (h *ServiceHandler) getJobUpdateDiff(
	ctx context.Context,
	request *api.JobUpdateRequest,
) (*api.Result, *auroraError) {

	respoolID, err := h.respoolLoader.Load(ctx)
	if err != nil {
		return nil, auroraErrorf("load respool: %s", err)
	}

	jobKey := request.GetTaskConfig().GetJob()
	jobID, err := h.getJobID(ctx, jobKey)
	if err != nil {
		return nil, auroraErrorf("get jobID: %s", err)
	}

	jobSummary, err := h.getJobInfoSummary(ctx, jobID)
	if err != nil {
		return nil, auroraErrorf("get job summary: %s", err)
	}

	jobSpec, err := atop.NewJobSpecFromJobUpdateRequest(request, respoolID)
	if err != nil {
		return nil, auroraErrorf("new job spec: %s", err)
	}

	resp, err := h.jobClient.GetReplaceJobDiff(
		ctx,
		&statelesssvc.GetReplaceJobDiffRequest{
			JobId:   jobID,
			Version: jobSummary.GetStatus().GetVersion(),
			Spec:    jobSpec,
		})
	if err != nil {
		return nil, auroraErrorf("get replace job diff: %s", err)
	}

	return &api.Result{
		GetJobUpdateDiffResult: &api.GetJobUpdateDiffResult{
			Add: []*api.ConfigGroup{{
				Instances: ptoa.NewRange(resp.GetInstancesAdded()),
			}},
			Update: []*api.ConfigGroup{{
				Instances: ptoa.NewRange(resp.GetInstancesUpdated()),
			}},
			Remove: []*api.ConfigGroup{{
				Instances: ptoa.NewRange(resp.GetInstancesRemoved()),
			}},
			Unchanged: []*api.ConfigGroup{{
				Instances: ptoa.NewRange(resp.GetInstancesUnchanged()),
			}},
		},
	}, nil
}

// GetTierConfigs is a no-op. It is only used to determine liveness of the scheduler.
func (h *ServiceHandler) GetTierConfigs(
	ctx context.Context,
) (*api.Response, error) {

	return newResponse(&api.Result{
		GetTierConfigResult: &api.GetTierConfigResult{
			DefaultTierName: ptr.String(common.Preemptible),
			Tiers: []*api.TierConfig{
				{
					Name: ptr.String(common.Revocable),
					Settings: map[string]string{
						common.Preemptible: "true",
						common.Revocable:   "true",
					},
				},
				{
					Name: ptr.String(common.Preferred),
					Settings: map[string]string{
						common.Preemptible: "false",
						common.Revocable:   "false",
					},
				},
				{
					Name: ptr.String(common.Preemptible),
					Settings: map[string]string{
						common.Preemptible: "true",
						common.Revocable:   "false",
					},
				},
			},
		},
	}, nil), nil
}

// KillTasks initiates a kill on tasks.
func (h *ServiceHandler) KillTasks(
	ctx context.Context,
	job *api.JobKey,
	instances map[int32]struct{},
	message *string,
) (*api.Response, error) {

	result, err := h.killTasks(ctx, job, instances, message)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"job":       job,
				"instances": instances,
				"message":   message,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("KillTasks error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) killTasks(
	ctx context.Context,
	job *api.JobKey,
	instances map[int32]struct{},
	message *string,
) (*api.Result, *auroraError) {

	id, err := h.getJobID(ctx, job)
	if err != nil {
		return nil, auroraErrorf("get job id: %s", err)
	}
	summary, err := h.getJobInfoSummary(ctx, id)
	if err != nil {
		return nil, auroraErrorf("get job info summary: %s", err)
	}

	stopAll := false
	if uint32(len(instances)) == summary.GetInstanceCount() {
		// Sanity check to make sure we don't stop everything if instances
		// are out of bounds.
		low, high := instanceBounds(instances)
		if low == 0 && high == int32(len(instances)-1) {
			stopAll = true
		}
	}

	if stopAll {
		// If all instances are specified, issue a single StopJob instead of
		// multiple StopPods for performance reasons.
		req := &statelesssvc.StopJobRequest{
			JobId:   id,
			Version: summary.GetStatus().GetVersion(),
		}
		if _, err := h.jobClient.StopJob(ctx, req); err != nil {
			return nil, auroraErrorf("stop job: %s", err)
		}
	} else {
		if err := h.stopPodsConcurrently(ctx, id, instances); err != nil {
			return nil, auroraErrorf("stop pods in parallel: %s", err)
		}
	}
	return &api.Result{}, nil
}

func (h *ServiceHandler) stopPodsConcurrently(
	ctx context.Context,
	id *peloton.JobID,
	instances map[int32]struct{},
) error {

	var inputs []interface{}
	for i := range instances {
		inputs = append(inputs, i)
	}

	f := func(ctx context.Context, input interface{}) (interface{}, error) {
		instanceID := input.(int32)
		name := util.CreatePelotonTaskID(id.GetValue(), uint32(instanceID))
		req := &podsvc.StopPodRequest{
			PodName: &peloton.PodName{Value: name},
		}

		resp, err := h.podClient.StopPod(ctx, req)
		if err != nil {
			return nil, fmt.Errorf("stop pod %d: %s", instanceID, err)
		}

		return resp, nil
	}

	_, err := concurrency.Map(
		ctx,
		concurrency.MapperFunc(f),
		inputs,
		h.config.StopPodWorkers)

	return err
}

// instanceBounds returns the lowest and highest instance id of
// instances. If instances is empty, returns -1.
func instanceBounds(instances map[int32]struct{}) (low, high int32) {
	if len(instances) == 0 {
		return -1, -1
	}
	for i := range instances {
		if i < low {
			low = i
		}
		if i > high {
			high = i
		}
	}
	return low, high
}

// StartJobUpdate starts update of the existing service job.
func (h *ServiceHandler) StartJobUpdate(
	ctx context.Context,
	request *api.JobUpdateRequest,
	message *string,
) (*api.Response, error) {

	result, err := h.startJobUpdate(ctx, request, message)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"request": request,
				"message": message,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("StartJobUpdate error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) startJobUpdate(
	ctx context.Context,
	request *api.JobUpdateRequest,
	message *string,
) (*api.Result, *auroraError) {

	respoolID, err := h.respoolLoader.Load(ctx)
	if err != nil {
		return nil, auroraErrorf("load respool: %s", err)
	}

	jobKey := request.GetTaskConfig().GetJob()

	jobSpec, err := atop.NewJobSpecFromJobUpdateRequest(request, respoolID)
	if err != nil {
		return nil, auroraErrorf("new job spec: %s", err)
	}

	// TODO(codyg): We'll use the new job's entity version as the update id.
	// Not sure if this will work.
	var newVersion *peloton.EntityVersion

	id, err := h.getJobID(ctx, jobKey)
	if err != nil {
		if yarpcerrors.IsNotFound(err) {
			// Job does not exist. Create it.
			req := &statelesssvc.CreateJobRequest{
				Spec: jobSpec,
			}
			resp, err := h.jobClient.CreateJob(ctx, req)
			if err != nil {
				if yarpcerrors.IsAlreadyExists(err) {
					// Upgrade conflict.
					return nil, auroraErrorf(
						"create job: %s", err).
						code(api.ResponseCodeInvalidRequest)
				}
				return nil, auroraErrorf("create job: %s", err)
			}
			newVersion = resp.GetVersion()
		} else {
			return nil, auroraErrorf("get job id: %s", err)
		}
	} else {
		// Job already exists. Replace it.
		v, err := h.getCurrentJobVersion(ctx, id)
		if err != nil {
			return nil, auroraErrorf("get current job version: %s", err)
		}

		d := &opaquedata.Data{
			UpdateID: uuid.New(),
		}
		if request.GetSettings().GetBlockIfNoPulsesAfterMs() > 0 {
			d.AppendUpdateAction(opaquedata.StartPulsed)
		}
		od, err := d.Serialize()
		if err != nil {
			return nil, auroraErrorf("serialize opaque data: %s", err)
		}

		req := &statelesssvc.ReplaceJobRequest{
			JobId:      id,
			Spec:       jobSpec,
			UpdateSpec: atop.NewUpdateSpec(request.GetSettings()),
			Version:    v,
			OpaqueData: od,
		}
		resp, err := h.jobClient.ReplaceJob(ctx, req)
		if err != nil {
			if yarpcerrors.IsAborted(err) {
				// Upgrade conflict.
				return nil, auroraErrorf(
					"replace job: %s", err).
					code(api.ResponseCodeInvalidRequest)
			}
			return nil, auroraErrorf("replace job: %s", err)
		}
		newVersion = resp.GetVersion()
	}

	return &api.Result{
		StartJobUpdateResult: &api.StartJobUpdateResult{
			Key: &api.JobUpdateKey{
				Job: jobKey,
				ID:  ptr.String(newVersion.String()),
			},
			UpdateSummary: nil, // TODO(codyg): Should we set this?
		},
	}, nil
}

// PauseJobUpdate pauses the specified job update. Can be resumed by resumeUpdate call.
func (h *ServiceHandler) PauseJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Response, error) {

	result, err := h.pauseJobUpdate(ctx, key, message)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key":     key,
				"message": message,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("PauseJobUpdate error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) pauseJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Result, *auroraError) {

	id, err := h.getJobID(ctx, key.GetJob())
	if err != nil {
		return nil, auroraErrorf("get job id: %s", err)
	}
	v, aerr := h.matchJobUpdateID(ctx, id, key.GetID())
	if aerr != nil {
		return nil, aerr
	}
	req := &statelesssvc.PauseJobWorkflowRequest{
		JobId:   id,
		Version: v,
	}
	if _, err := h.jobClient.PauseJobWorkflow(ctx, req); err != nil {
		return nil, auroraErrorf("pause job workflow: %s", err)
	}
	return &api.Result{}, nil
}

// ResumeJobUpdate resumes progress of a previously paused job update.
func (h *ServiceHandler) ResumeJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Response, error) {

	result, err := h.resumeJobUpdate(ctx, key, message)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key":     key,
				"message": message,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("ResumeJobUpdate error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) resumeJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Result, *auroraError) {

	id, err := h.getJobID(ctx, key.GetJob())
	if err != nil {
		return nil, auroraErrorf("get job id: %s", err)
	}
	v, aerr := h.matchJobUpdateID(ctx, id, key.GetID())
	if aerr != nil {
		return nil, aerr
	}
	req := &statelesssvc.ResumeJobWorkflowRequest{
		JobId:   id,
		Version: v,
	}
	if _, err := h.jobClient.ResumeJobWorkflow(ctx, req); err != nil {
		return nil, auroraErrorf("resume job workflow: %s", err)
	}
	return &api.Result{}, nil
}

// AbortJobUpdate permanently aborts the job update. Does not remove the update history.
func (h *ServiceHandler) AbortJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Response, error) {

	result, err := h.abortJobUpdate(ctx, key, message)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key":     key,
				"message": message,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("AbortJobUpdate error")
	}
	return newResponse(result, err), nil
}

func (h *ServiceHandler) abortJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Result, *auroraError) {

	id, err := h.getJobID(ctx, key.GetJob())
	if err != nil {
		return nil, auroraErrorf("get job id: %s", err)
	}
	v, aerr := h.matchJobUpdateID(ctx, id, key.GetID())
	if aerr != nil {
		return nil, aerr
	}
	req := &statelesssvc.AbortJobWorkflowRequest{
		JobId:   id,
		Version: v,
	}
	if _, err := h.jobClient.AbortJobWorkflow(ctx, req); err != nil {
		return nil, auroraErrorf("abort job workflow: %s", err)
	}
	return &api.Result{}, nil
}

// RollbackJobUpdate rollbacks the specified active job update to the initial state.
func (h *ServiceHandler) RollbackJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Response, error) {

	result, err := h.rollbackJobUpdate(ctx, key, message)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key":     key,
				"message": message,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("RollbackJobUpdate error")
	}
	return newResponse(result, err), nil
}

// _validRollbackStatuses enumerates the statuses which a job update must be in
// for rollback to be valid.
var _validRollbackStatuses = common.NewJobUpdateStatusSet(
	api.JobUpdateStatusRollingForward,
	api.JobUpdateStatusRollForwardPaused,
	api.JobUpdateStatusRollForwardAwaitingPulse,
)

func (h *ServiceHandler) rollbackJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
	message *string,
) (*api.Result, *auroraError) {

	id, err := h.getJobID(ctx, key.GetJob())
	if err != nil {
		return nil, auroraErrorf("get job id: %s", err)
	}

	w, err := h.getWorkflowInfo(ctx, id)
	if err != nil {
		return nil, auroraErrorf("get workflow info: %s", err)
	}

	d, err := opaquedata.Deserialize(w.GetOpaqueData())
	if err != nil {
		return nil, auroraErrorf("deserialize opaque data: %s", err)
	}

	if d.UpdateID != key.GetID() {
		return nil, auroraErrorf(
			"update id does not match current update").
			code(api.ResponseCodeInvalidRequest)
	}

	status, err := ptoa.NewJobUpdateStatus(w.GetStatus().GetState(), d)
	if err != nil {
		return nil, auroraErrorf("new job update status: %s", err)
	}
	if !_validRollbackStatuses.Has(status) {
		return nil, auroraErrorf(
			"invalid rollback: update must be in %s", _validRollbackStatuses).
			code(api.ResponseCodeInvalidRequest)
	}

	d.AppendUpdateAction(opaquedata.Rollback)
	od, err := d.Serialize()
	if err != nil {
		return nil, auroraErrorf("serialize opaque data: %s", err)
	}

	prevJob, err := h.getFullJobInfoByVersion(ctx, id, w.GetStatus().GetPrevVersion())
	if err != nil {
		return nil, auroraErrorf("get previous job: %s", err)
	}

	req := &statelesssvc.ReplaceJobRequest{
		JobId:   id,
		Version: w.GetStatus().GetVersion(),
		Spec:    prevJob.GetSpec(),
		//Secrets: nil,
		UpdateSpec: w.GetUpdateSpec(),
		OpaqueData: od,
	}
	if _, err := h.jobClient.ReplaceJob(ctx, req); err != nil {
		return nil, auroraErrorf("replace job: %s", err)
	}
	return &api.Result{}, nil
}

// PulseJobUpdate allows progress of the job update in case blockIfNoPulsesAfterMs is specified in
// JobUpdateSettings. Unblocks progress if the update was previously blocked.
// Responds with ResponseCode.INVALID_REQUEST in case an unknown update key is specified.
func (h *ServiceHandler) PulseJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
) (*api.Response, error) {

	result, err := h.pulseJobUpdate(ctx, key)
	if err != nil {
		log.WithFields(log.Fields{
			"params": log.Fields{
				"key": key,
			},
			"code":  err.responseCode,
			"error": err.msg,
		}).Error("PulseJobUpdate error")
	}
	return newResponse(result, err), nil
}

// _validPulseStatuses enumerates the statuses which a job update must be in
// for pulse to be valid.
var _validPulseStatuses = common.NewJobUpdateStatusSet(
	api.JobUpdateStatusRollForwardAwaitingPulse,
	api.JobUpdateStatusRollBackAwaitingPulse,
)

func (h *ServiceHandler) pulseJobUpdate(
	ctx context.Context,
	key *api.JobUpdateKey,
) (*api.Result, *auroraError) {

	id, err := h.getJobID(ctx, key.GetJob())
	if err != nil {
		aerr := auroraErrorf("get job id: %s", err)
		if yarpcerrors.IsNotFound(err) {
			// Unknown update.
			// TODO(codyg): We should support some form of update ID.
			aerr.code(api.ResponseCodeInvalidRequest)
		}
		return nil, aerr
	}

	w, err := h.getWorkflowInfo(ctx, id)
	if err != nil {
		return nil, auroraErrorf("get workflow info: %s", err)
	}

	d, err := opaquedata.Deserialize(w.GetOpaqueData())
	if err != nil {
		return nil, auroraErrorf("deserialize opaque data: %s", err)
	}

	if d.UpdateID != key.GetID() {
		return nil, auroraErrorf("update id does not match current update").
			code(api.ResponseCodeInvalidRequest)
	}

	status, err := ptoa.NewJobUpdateStatus(w.GetStatus().GetState(), d)
	if err != nil {
		return nil, auroraErrorf("new job update status: %s", err)
	}

	// Only resume if we're in a valid status. Else, pulseJobUpdate is
	// a no-op.
	if _validPulseStatuses.Has(status) {
		d.AppendUpdateAction(opaquedata.Pulse)
		od, err := d.Serialize()
		if err != nil {
			return nil, auroraErrorf("serialize opaque data: %s", err)
		}

		req := &statelesssvc.ResumeJobWorkflowRequest{
			JobId:      id,
			Version:    w.GetStatus().GetVersion(),
			OpaqueData: od,
		}
		if _, err := h.jobClient.ResumeJobWorkflow(ctx, req); err != nil {
			return nil, auroraErrorf("resume job workflow: %s", err)
		}
	}

	return &api.Result{
		PulseJobUpdateResult: &api.PulseJobUpdateResult{
			Status: api.JobUpdatePulseStatusOk.Ptr(),
		},
	}, nil
}

// getJobUpdateDetails gets job detils concurrently
func (h *ServiceHandler) getJobUpdateDetails(
	ctx context.Context,
	jobUpdateQuery *api.JobUpdateQuery,
	summaryOnly bool,
) ([]*api.JobUpdateDetails, *auroraError) {
	var jobUpdateDetails []*api.JobUpdateDetails

	jobSummaries, err := h.getJobSummariesFromJobUpdateQuery(
		ctx,
		jobUpdateQuery)
	if err != nil {
		return jobUpdateDetails, nil
	}

	var inputs []interface{}
	for _, j := range jobSummaries {
		inputs = append(inputs, j)
	}

	f := func(ctx context.Context, input interface{}) (interface{}, error) {
		return h.getJobUpdateDetail(
			ctx,
			jobUpdateQuery,
			input.(*stateless.JobSummary),
			summaryOnly)
	}

	outputs, err := concurrency.Map(
		ctx,
		concurrency.MapperFunc(f),
		inputs,
		h.config.GetJobUpdateWorkers)
	if err != nil {
		return nil, auroraErrorf("failed to get jobUpdateDetails: %s", err)
	}

	for _, o := range outputs {
		if o.(*api.JobUpdateDetails) == nil {
			continue
		}

		jobUpdateDetails = append(jobUpdateDetails, o.(*api.JobUpdateDetails))
	}

	return jobUpdateDetails, nil
}

// getJobUpdateDetail get details of most recent workflow of the job
func (h *ServiceHandler) getJobUpdateDetail(
	ctx context.Context,
	jobUpdateQuery *api.JobUpdateQuery,
	jobSummary *stateless.JobSummary,
	summaryOnly bool,
) (*api.JobUpdateDetails, error) {

	// Get job update
	resp, err := h.jobClient.GetJob(
		ctx,
		&statelesssvc.GetJobRequest{
			JobId: jobSummary.GetJobId(),
		})
	if err != nil {
		return nil, fmt.Errorf("getJobUpdate failed: %s", err)
	}

	// No workflow exists for a job
	if resp.GetWorkflowInfo().GetStatus().GetState() ==
		stateless.WorkflowState_WORKFLOW_STATE_INVALID {
		return nil, nil
	}

	// INITIALIZED workflows are ignored to take action upon because Aurora
	// does not support this state
	// Assumption is that jobmgr's goal state engine will process these
	// workflows and take appropriate action to make progress on
	// workflow operations
	if resp.GetWorkflowInfo().GetStatus().GetState() ==
		stateless.WorkflowState_WORKFLOW_STATE_INITIALIZED {
		return nil, nil /* update is filtered */
	}

	// Filter by job update state
	ok, err := isUpdateInfoInStatuses(
		resp.GetWorkflowInfo(),
		jobUpdateQuery.GetUpdateStatuses())
	if err != nil {
		return nil, err
	}
	if !ok {
		return nil, nil /* update is filtered */
	}

	// Get Job Update Summary
	jobKey, err := ptoa.NewJobKey(jobSummary.GetName())
	if err != nil {
		return nil, err
	}

	jobUpdateSummary, err := ptoa.NewJobUpdateSummary(
		jobKey,
		resp.GetWorkflowInfo())
	if err != nil {
		return nil, err
	}

	var jobUpdateEvents []*api.JobUpdateEvent
	var jobInstancesUpdateEvents []*api.JobInstanceUpdateEvent
	var jobInstructions *api.JobUpdateInstructions

	// Get job update details if summaryOnly is set false
	if !summaryOnly {
		opaqueData, err := opaquedata.Deserialize(resp.GetWorkflowInfo().GetOpaqueData())
		if err != nil {
			return nil, fmt.Errorf("deserialize opaque data: %s", err)
		}

		// Get Job Update Events
		for _, updateEvent := range resp.GetWorkflowInfo().GetEvents() {
			jobUpdateEvent, err := ptoa.NewJobUpdateEvent(
				updateEvent,
				opaqueData)
			if err != nil {
				return nil, fmt.Errorf("unable to get job update event %s", err)
			}

			jobUpdateEvents = append(jobUpdateEvents, jobUpdateEvent)
		}

		jobInstructions = ptoa.NewJobUpdateInstructions(resp.GetWorkflowInfo())

		instancesInUpdate := append(resp.GetWorkflowInfo().GetRestartRanges(),
			resp.GetWorkflowInfo().GetInstancesUpdated()...)
		instancesInUpdate = append(instancesInUpdate,
			resp.GetWorkflowInfo().GetInstancesAdded()...)
		instancesInUpdate = append(instancesInUpdate,
			resp.GetWorkflowInfo().GetInstancesRemoved()...)

		// Get Job Instance Update Events
		jobInstancesUpdateEvents, err = h.getJobInstanceUpdateEvents(
			ctx,
			instancesInUpdate,
			jobSummary,
		)
		if err != nil {
			return nil, fmt.Errorf("unable to get instance workflow events %s", err)
		}
	}

	return &api.JobUpdateDetails{
		Update: &api.JobUpdate{
			Summary:      jobUpdateSummary,
			Instructions: jobInstructions,
		},
		UpdateEvents:   jobUpdateEvents,
		InstanceEvents: jobInstancesUpdateEvents,
	}, nil
}

// getJobInstanceUpdateEvents gets the update state change events for an instance
func (h *ServiceHandler) getJobInstanceUpdateEvents(
	ctx context.Context,
	instanceRanges []*pod.InstanceIDRange,
	jobSummary *stateless.JobSummary,
) ([]*api.JobInstanceUpdateEvent, error) {

	var inputs []interface{}
	for _, instanceRange := range instanceRanges {
		for j := instanceRange.From; j < instanceRange.To; j++ {
			inputs = append(inputs, j)
		}
	}

	f := func(ctx context.Context, input interface{}) (interface{}, error) {
		resp, err := h.jobClient.GetWorkflowEvents(
			ctx,
			&statelesssvc.GetWorkflowEventsRequest{
				JobId:      jobSummary.GetJobId(),
				InstanceId: input.(uint32),
			})
		if err != nil {
			return nil, err
		}

		var jobInstanceUpdateEvents []*api.JobInstanceUpdateEvent
		for _, instanceEvent := range resp.GetEvents() {
			jobInstanceUpdateEvent, err := ptoa.NewJobInstanceUpdateEvent(input.(uint32), instanceEvent)
			if err != nil {
				return nil, err
			}

			jobInstanceUpdateEvents = append(jobInstanceUpdateEvents, jobInstanceUpdateEvent)
		}

		return jobInstanceUpdateEvents, nil
	}

	outputs, err := concurrency.Map(
		ctx,
		concurrency.MapperFunc(f),
		inputs,
		h.config.GetJobUpdateWorkers)
	if err != nil {
		return nil, err
	}

	var jobInstancesUpdateEvents []*api.JobInstanceUpdateEvent
	for _, o := range outputs {
		jobInstancesUpdateEvents = append(jobInstancesUpdateEvents, o.([]*api.JobInstanceUpdateEvent)...)
	}

	return jobInstancesUpdateEvents, nil
}

// getJobSummariesFromJobUpdateQuery queries peloton jobs based on
// Aurora's JobUpdateQuery.
func (h *ServiceHandler) getJobSummariesFromJobUpdateQuery(
	ctx context.Context,
	q *api.JobUpdateQuery,
) ([]*stateless.JobSummary, error) {

	if q.IsSetJobKey() {
		return h.getJobSummaries(ctx, q.GetJobKey())
	}

	return h.queryJobSummaries(ctx, q.GetRole(), "", "")
}

// isUpdateInfoInStatuses checks if job update state is present
// in expected list of job update states
func isUpdateInfoInStatuses(
	u *stateless.WorkflowInfo,
	statuses map[api.JobUpdateStatus]struct{},
) (bool, error) {

	d, err := opaquedata.Deserialize(u.GetOpaqueData())
	if err != nil {
		return false, fmt.Errorf("deserialize opaque data: %s", err)
	}

	s, err := ptoa.NewJobUpdateStatus(u.GetStatus().GetState(), d)
	if err != nil {
		return false, fmt.Errorf("new job update status: %s", err)
	}

	_, ok := statuses[s]
	return ok, nil
}

// getJobID maps k to a job id.
//
// TODO: To be deprecated in favor of getJobSummaries.
// Aggregator expects job key environment to be set in response of
// GetJobUpdateDetails to filter by deployment_id. On filtering via job key
// role, original peloton job name is not known to set job key environment.
func (h *ServiceHandler) getJobID(
	ctx context.Context,
	k *api.JobKey,
) (*peloton.JobID, error) {
	req := &statelesssvc.GetJobIDFromJobNameRequest{
		JobName: atop.NewJobName(k),
	}
	resp, err := h.jobClient.GetJobIDFromJobName(ctx, req)
	if err != nil {
		return nil, err
	}
	// results are sorted chronologically, return the latest one
	return resp.GetJobId()[0], nil
}

// queryJobIDs takes optional job key components and returns the Peloton job ids
// which match the set parameters. E.g. queryJobIDs("myservice", "", "") will return
// job ids which match role=myservice.
func (h *ServiceHandler) queryJobIDs(
	ctx context.Context,
	role, env, name string,
) ([]*peloton.JobID, error) {

	if role != "" && env != "" && name != "" {
		// All job key components set, just use a job key query directly.
		id, err := h.getJobID(ctx, &api.JobKey{
			Role:        ptr.String(role),
			Environment: ptr.String(env),
			Name:        ptr.String(name),
		})
		if err != nil {
			return nil, err
		}
		return []*peloton.JobID{id}, nil
	}

	labels := label.BuildPartialAuroraJobKeyLabels(role, env, name)
	if len(labels) == 0 {
		// TODO(kevinxu): do we need to return all job ids in this case?
		return nil, errors.New("no filters set")
	}

	req := &statelesssvc.QueryJobsRequest{
		Spec: &stateless.QuerySpec{
			Labels: labels,
		},
	}
	resp, err := h.jobClient.QueryJobs(ctx, req)
	if err != nil {
		return nil, err
	}
	jobIDs := make([]*peloton.JobID, 0, len(resp.GetRecords()))
	for _, record := range resp.GetRecords() {
		jobIDs = append(jobIDs, record.GetJobId())
	}
	return jobIDs, nil
}

// getJobSummaries returns Peloton JobSummary based on Aurora JobKey passed in.
func (h *ServiceHandler) getJobSummaries(
	ctx context.Context,
	k *api.JobKey,
) ([]*stateless.JobSummary, error) {
	req := &statelesssvc.GetJobIDFromJobNameRequest{
		JobName: atop.NewJobName(k),
	}

	resp, err := h.jobClient.GetJobIDFromJobName(ctx, req)
	if err != nil {
		return nil, err
	}

	// results are sorted chronologically, return the latest one
	return []*stateless.JobSummary{
		{
			JobId: resp.GetJobId()[0],
			Name:  atop.NewJobName(k),
		},
	}, nil
}

// queryJobSummaries takes optional job key components and returns the Peloton
// job summaries which match the set parameters. E.g. queryJobSummaries("myservice", "", "")
// will return summaries which match role=myservice.
func (h *ServiceHandler) queryJobSummaries(
	ctx context.Context,
	role, env, name string,
) ([]*stateless.JobSummary, error) {
	req := &statelesssvc.QueryJobsRequest{
		Spec: &stateless.QuerySpec{
			Labels: label.BuildPartialAuroraJobKeyLabels(role, env, name),
		},
	}
	resp, err := h.jobClient.QueryJobs(ctx, req)
	if err != nil {
		return nil, err
	}
	return resp.GetRecords(), nil
}

// getJobIDsFromTaskQuery queries peloton job ids based on aurora TaskQuery.
// Note that it will not throw error when no job is found. The current
// behavior for querying:
// 1. If TaskQuery.JobKeys is present, the job keys there to query job ids
// 2. Otherwise use TaskQuery.Role, TaskQuery.Environment and
//    TaskQuery.JobName to construct a job key (those 3 fields may not be
//    all present), and use it to query job ids.
func (h *ServiceHandler) getJobIDsFromTaskQuery(
	ctx context.Context,
	query *api.TaskQuery,
) ([]*peloton.JobID, error) {
	if query == nil {
		return nil, errors.New("task query is nil")
	}

	// use job_keys to query if present
	if query.IsSetJobKeys() {
		var ids []*peloton.JobID
		for _, jobKey := range query.GetJobKeys() {
			id, err := h.getJobID(ctx, jobKey)
			if err != nil {
				if yarpcerrors.IsNotFound(err) {
					continue
				}
				return nil, errors.Wrapf(err, "get job id for %q", jobKey)
			}
			ids = append(ids, id)
		}
		return ids, nil
	}

	ids, err := h.queryJobIDs(
		ctx, query.GetRole(), query.GetEnvironment(), query.GetJobName())
	if err != nil {
		if yarpcerrors.IsNotFound(err) {
			// ignore not found error and return empty job ids
			return nil, nil
		}
		return nil, errors.Wrapf(err, "get job ids")
	}
	return ids, nil
}

func (h *ServiceHandler) getCurrentJobVersion(
	ctx context.Context,
	id *peloton.JobID,
) (*peloton.EntityVersion, error) {
	summary, err := h.getJobInfoSummary(ctx, id)
	if err != nil {
		return nil, err
	}
	return summary.GetStatus().GetVersion(), nil
}

// matchJobUpdateID matches a jobID workflow against updateID. Returns the entity
// version the workflow is moving towards. If the current workflow does not
// match updateID, returns an INVALID_REQUEST Aurora error.
func (h *ServiceHandler) matchJobUpdateID(
	ctx context.Context,
	jobID *peloton.JobID,
	updateID string,
) (*peloton.EntityVersion, *auroraError) {

	w, err := h.getWorkflowInfo(ctx, jobID)
	if err != nil {
		return nil, auroraErrorf("get workflow info: %s", err)
	}
	d, err := opaquedata.Deserialize(w.GetOpaqueData())
	if err != nil {
		return nil, auroraErrorf("deserialize opaque data: %s", err)
	}
	if d.UpdateID != updateID {
		return nil, auroraErrorf("update id does not match current update").
			code(api.ResponseCodeInvalidRequest)
	}
	return w.GetStatus().GetVersion(), nil
}

// getJobInfo calls jobmgr to get JobInfo based on JobID.
func (h *ServiceHandler) getJobInfo(
	ctx context.Context,
	jobID *peloton.JobID,
) (*stateless.JobInfo, error) {
	req := &statelesssvc.GetJobRequest{
		JobId:       jobID,
		SummaryOnly: false,
	}
	resp, err := h.jobClient.GetJob(ctx, req)
	if err != nil {
		return nil, err
	}
	return resp.GetJobInfo(), nil
}

func (h *ServiceHandler) getFullJobInfoByVersion(
	ctx context.Context,
	jobID *peloton.JobID,
	v *peloton.EntityVersion,
) (*stateless.JobInfo, error) {
	req := &statelesssvc.GetJobRequest{
		JobId:   jobID,
		Version: v,
	}
	resp, err := h.jobClient.GetJob(ctx, req)
	if err != nil {
		return nil, err
	}
	return resp.GetJobInfo(), nil
}

// getJobInfoSummary calls jobmgr to get JobSummary based on JobID.
func (h *ServiceHandler) getJobInfoSummary(
	ctx context.Context,
	jobID *peloton.JobID,
) (*stateless.JobSummary, error) {
	req := &statelesssvc.GetJobRequest{
		JobId:       jobID,
		SummaryOnly: true,
	}
	resp, err := h.jobClient.GetJob(ctx, req)
	if err != nil {
		return nil, err
	}
	return resp.GetSummary(), nil
}

func (h *ServiceHandler) getWorkflowInfo(
	ctx context.Context,
	jobID *peloton.JobID,
) (*stateless.WorkflowInfo, error) {

	req := &statelesssvc.GetJobRequest{
		JobId: jobID,
	}

	resp, err := h.jobClient.GetJob(ctx, req)
	if err != nil {
		return nil, err
	}

	return resp.GetWorkflowInfo(), nil
}

// queryPods calls jobmgr to query a list of PodInfo based on input JobID.
func (h *ServiceHandler) queryPods(
	ctx context.Context,
	jobID *peloton.JobID,
	states []pod.PodState,
	limit uint32,
) ([]*pod.PodInfo, error) {
	req := &statelesssvc.QueryPodsRequest{
		JobId: jobID,
		Spec: &pod.QuerySpec{
			PodStates: states,
			Pagination: &pbquery.PaginationSpec{
				Limit: limit,
			},
		},
		Pagination: &pbquery.PaginationSpec{
			Limit: limit,
		},
	}
	resp, err := h.jobClient.QueryPods(ctx, req)
	if err != nil {
		return nil, err
	}
	return resp.GetPods(), nil
}

// getPodEvents calls jobmgr to get a list of PodEvent based on PodName.
func (h *ServiceHandler) getPodEvents(
	ctx context.Context,
	podName *peloton.PodName,
	podID *peloton.PodID,
) ([]*pod.PodEvent, error) {
	req := &podsvc.GetPodEventsRequest{
		PodName: podName,
		PodId:   podID,
	}
	resp, err := h.podClient.GetPodEvents(ctx, req)
	if err != nil {
		return nil, err
	}
	return resp.GetEvents(), nil
}
